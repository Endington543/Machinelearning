{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "played-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3772 - val_loss: 0.1857\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1766 - val_loss: 0.1521\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1480 - val_loss: 0.1327\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1306 - val_loss: 0.1207\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1199 - val_loss: 0.1131\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1128 - val_loss: 0.1075\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1075 - val_loss: 0.1031\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1036 - val_loss: 0.0998\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1003 - val_loss: 0.0975\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0957\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0968 - val_loss: 0.0946\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0939\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0952 - val_loss: 0.0934\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0944 - val_loss: 0.0931\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0941 - val_loss: 0.0929\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0919\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0917\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0916\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "veterinary-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3884 - val_loss: 0.1994\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1897 - val_loss: 0.1624\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1584 - val_loss: 0.1443\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 0.1331\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1320 - val_loss: 0.1248\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1248 - val_loss: 0.1190\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1189 - val_loss: 0.1147\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1152 - val_loss: 0.1117\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1121 - val_loss: 0.1091\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1099 - val_loss: 0.1075\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1084 - val_loss: 0.1063\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1072 - val_loss: 0.1054\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1065 - val_loss: 0.1047\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1059 - val_loss: 0.1042\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1052 - val_loss: 0.1037\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1050 - val_loss: 0.1033\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1043 - val_loss: 0.1029\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1041 - val_loss: 0.1025\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1037 - val_loss: 0.1022\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1035 - val_loss: 0.1020\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1030 - val_loss: 0.1017\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1028 - val_loss: 0.1014\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1024 - val_loss: 0.1012\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1010\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1020 - val_loss: 0.1008\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1018 - val_loss: 0.1006\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1016 - val_loss: 0.1004\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1014 - val_loss: 0.1002\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1013 - val_loss: 0.1000\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0999\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0998\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1008 - val_loss: 0.0996\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1006 - val_loss: 0.0995\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1005 - val_loss: 0.0993\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1003 - val_loss: 0.0992\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1003 - val_loss: 0.0991\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1002 - val_loss: 0.0990\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.0989\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.0988\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0987\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0998 - val_loss: 0.0985\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0985\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.0984\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0995 - val_loss: 0.0984\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0996 - val_loss: 0.0982\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0994 - val_loss: 0.0982\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0991 - val_loss: 0.0981\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0991 - val_loss: 0.0979\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0988 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0992 - val_loss: 0.0978\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0977\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0988 - val_loss: 0.0976\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0976\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0987 - val_loss: 0.0974\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0985 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0973\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0984 - val_loss: 0.0973\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0973\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0968\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0968\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.0967\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0976 - val_loss: 0.0966\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.0965\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0975 - val_loss: 0.0965\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0964\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0961\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0960\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0961\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0960\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0959\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0958\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharp-cheese",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "present-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.2003\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1897 - val_loss: 0.1634\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1587 - val_loss: 0.1424\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1406 - val_loss: 0.1302\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1294 - val_loss: 0.1221\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1221 - val_loss: 0.1162\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1165 - val_loss: 0.1123\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1127 - val_loss: 0.1096\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1103 - val_loss: 0.1078\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1086 - val_loss: 0.1065\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1075 - val_loss: 0.1055\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1065 - val_loss: 0.1048\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1057 - val_loss: 0.1041\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1051 - val_loss: 0.1036\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1048 - val_loss: 0.1032\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1044 - val_loss: 0.1028\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1039 - val_loss: 0.1024\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1035 - val_loss: 0.1021\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1032 - val_loss: 0.1019\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1031 - val_loss: 0.1016\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1026 - val_loss: 0.1013\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1023 - val_loss: 0.1011\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1023 - val_loss: 0.1008\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1018 - val_loss: 0.1006\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1017 - val_loss: 0.1005\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1016 - val_loss: 0.1002\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1012 - val_loss: 0.1001\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1010 - val_loss: 0.0999\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0998\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1009 - val_loss: 0.0996\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1005 - val_loss: 0.0995\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0994\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0990\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0989\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0998 - val_loss: 0.0988\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0999 - val_loss: 0.0988\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0999 - val_loss: 0.0987\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0985\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.0985\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0993 - val_loss: 0.0982\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.0982\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.0980\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0989 - val_loss: 0.0979\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0989 - val_loss: 0.0978\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0988 - val_loss: 0.0976\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0975\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0974\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0985 - val_loss: 0.0974\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0983 - val_loss: 0.0973\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0983 - val_loss: 0.0972\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0984 - val_loss: 0.0972\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0972\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0971\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0979 - val_loss: 0.0970\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - val_loss: 0.0970\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - val_loss: 0.0969\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0969\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0968\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0975 - val_loss: 0.0966\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0975 - val_loss: 0.0966\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0965\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.0965\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0962\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0964\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0963\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0962\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0962\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0961\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0960\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0968 - val_loss: 0.0960\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0968 - val_loss: 0.0959\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aware-schedule",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (AutoEncoder.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    encoding_dim = 784 128\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "criminal-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3318 - val_loss: 0.1638\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1536 - val_loss: 0.1328\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1315 - val_loss: 0.1225\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1219 - val_loss: 0.1167\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1157 - val_loss: 0.1102\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1107 - val_loss: 0.1062\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1067 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1015\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.0999\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.0977\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.0967\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0952\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.0940\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0948 - val_loss: 0.0931\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0936 - val_loss: 0.0919\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0918\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.0906\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0914 - val_loss: 0.0901\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0910 - val_loss: 0.0898\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0902 - val_loss: 0.0894\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0898 - val_loss: 0.0890\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.0887\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0894 - val_loss: 0.0881\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0887 - val_loss: 0.0878\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.0873\n",
      "Epoch 27/100\n",
      " 81/235 [=========>....................] - ETA: 0s - loss: 0.0877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m autoencoder.fit(x_train, x_train,\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "human-colony",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-pepper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bacterial-designation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unique-protein",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aggressive-three",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(32, 128)' with type '<class 'tuple'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# This is our encoded (32-dimensional) input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# Retrieve the last layer of the autoencoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     input_layer_config.update(\n\u001b[1;32m    308\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[0;32m--> 309\u001b[0;31m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         input_tensor = backend.placeholder(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedKerasTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m       spec = tensor_spec.TensorSpec(\n\u001b[0m\u001b[1;32m   1247\u001b[0m           shape=shape, dtype=dtype, name=name)\n\u001b[1;32m   1248\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mconvertible\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         six.raise_from(\n\u001b[0m\u001b[1;32m    204\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[1;32m    205\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(32, 128)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "peripheral-shaft",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (AutoEncoder.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    encoding_dim = 32 128\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "particular-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3336 - val_loss: 0.1676\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1623 - val_loss: 0.1395\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1365 - val_loss: 0.1268\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1260 - val_loss: 0.1191\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1189 - val_loss: 0.1124\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1130 - val_loss: 0.1088\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1097 - val_loss: 0.1064\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1071 - val_loss: 0.1042\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1049 - val_loss: 0.1028\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1034 - val_loss: 0.1019\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1000\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1008 - val_loss: 0.0986\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0998 - val_loss: 0.0974\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0964\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0957\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0964 - val_loss: 0.0948\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0956 - val_loss: 0.0940\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0949 - val_loss: 0.0935\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0925\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0920 - val_loss: 0.0907\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0910 - val_loss: 0.0903\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0907 - val_loss: 0.0896\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0905 - val_loss: 0.0896\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0901 - val_loss: 0.0895\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0899 - val_loss: 0.0889\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0895 - val_loss: 0.0890\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0890 - val_loss: 0.0882\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0884\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0881\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0884 - val_loss: 0.0876\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0881 - val_loss: 0.0876\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0879 - val_loss: 0.0874\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0877 - val_loss: 0.0870\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0877 - val_loss: 0.0872\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0867\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0871 - val_loss: 0.0866\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - val_loss: 0.0862\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0867 - val_loss: 0.0863\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - val_loss: 0.0864\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - val_loss: 0.0859\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - val_loss: 0.0861\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0855\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - val_loss: 0.0858\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - val_loss: 0.0856\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - val_loss: 0.0855\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - val_loss: 0.0853\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0857 - val_loss: 0.0851\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0856 - val_loss: 0.0851\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0851\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0852 - val_loss: 0.0847\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0847\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0848\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0847\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0845\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0844\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0844\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0848 - val_loss: 0.0843\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0842\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - val_loss: 0.0842\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0843\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0841\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0844\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0840\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0841\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0840\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0843 - val_loss: 0.0839\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0839\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0836\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0838\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0837\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0836\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0837\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0837\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0835\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0835\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0834\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0833\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0833\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0832 - val_loss: 0.0831\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0829\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0831 - val_loss: 0.0828\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_90: expected shape=(None, 128), found shape=(None, 32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_90: expected shape=(None, 128), found shape=(None, 32)\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "accurate-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3395 - val_loss: 0.1663\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1579 - val_loss: 0.1354\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1333 - val_loss: 0.1226\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1222 - val_loss: 0.1146\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1153 - val_loss: 0.1097\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1098 - val_loss: 0.1069\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1071 - val_loss: 0.1039\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1043 - val_loss: 0.1016\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1003\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1006 - val_loss: 0.0988\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0996 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0963\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0957\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0944\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0914\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0917 - val_loss: 0.0903\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0909 - val_loss: 0.0897\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0898 - val_loss: 0.0888\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0888 - val_loss: 0.0879\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0884 - val_loss: 0.0875\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0879 - val_loss: 0.0873\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0876 - val_loss: 0.0869\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0874 - val_loss: 0.0863\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0870 - val_loss: 0.0861\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0865 - val_loss: 0.0857\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0865\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - val_loss: 0.0853\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - val_loss: 0.0850\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0856 - val_loss: 0.0852\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0848\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0849\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0843\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0841\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0838\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0836\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0826\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0829 - val_loss: 0.0825\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0827 - val_loss: 0.0826\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0824 - val_loss: 0.0819\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0821\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0820\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0819\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0817\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0815\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - val_loss: 0.0815\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0813\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0815 - val_loss: 0.0814\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0813 - val_loss: 0.0811\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0812\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0814\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0810\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0812\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0809\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0808\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0810 - val_loss: 0.0809\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0807\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0810\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0807\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0807 - val_loss: 0.0804\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0807 - val_loss: 0.0805\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0804\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0802\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0804 - val_loss: 0.0803\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0805 - val_loss: 0.0801\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0802 - val_loss: 0.0801\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0800\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0801\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0800\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0800\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0802\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0800 - val_loss: 0.0800\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0797\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0797\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0797 - val_loss: 0.0796\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - val_loss: 0.0797\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0799\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - val_loss: 0.0796\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0796 - val_loss: 0.0795\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decoded_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fundamental-titanium",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriental-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3378 - val_loss: 0.1620\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1531 - val_loss: 0.1333\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1316 - val_loss: 0.1230\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1225 - val_loss: 0.1152\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1153 - val_loss: 0.1101\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1104 - val_loss: 0.1067\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1069 - val_loss: 0.1036\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1044 - val_loss: 0.1018\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1023 - val_loss: 0.1000\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1009 - val_loss: 0.0985\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0995 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0982 - val_loss: 0.0961\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0968 - val_loss: 0.0951\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0962 - val_loss: 0.0945\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0919\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0922 - val_loss: 0.0909\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0916 - val_loss: 0.0903\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0909 - val_loss: 0.0897\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0905 - val_loss: 0.0894\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0900 - val_loss: 0.0892\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0899 - val_loss: 0.0887\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0894 - val_loss: 0.0885\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0890 - val_loss: 0.0884\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0883 - val_loss: 0.0876\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0880 - val_loss: 0.0871\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0878 - val_loss: 0.0873\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0866\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0873 - val_loss: 0.0864\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0861\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0867 - val_loss: 0.0860\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0866 - val_loss: 0.0858\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0863 - val_loss: 0.0854\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0862 - val_loss: 0.0851\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0850 - val_loss: 0.0848\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0851 - val_loss: 0.0843\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0848 - val_loss: 0.0845\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0842\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0850 - val_loss: 0.0841\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0846 - val_loss: 0.0847\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0842\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'genfromtxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genfromtxt' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "professional-guitar",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3428 - val_loss: 0.1663\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1559 - val_loss: 0.1349\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1331 - val_loss: 0.1226\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1225 - val_loss: 0.1165\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1167 - val_loss: 0.1117\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1122 - val_loss: 0.1081\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1082 - val_loss: 0.1048\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1055 - val_loss: 0.1026\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1032 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1013 - val_loss: 0.0990\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0998 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0984 - val_loss: 0.0965\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0972 - val_loss: 0.0950\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0960 - val_loss: 0.0942\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0951 - val_loss: 0.0937\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0935 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0924 - val_loss: 0.0910\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0905\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0909 - val_loss: 0.0899\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0904 - val_loss: 0.0895\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0900 - val_loss: 0.0896\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0893 - val_loss: 0.0888\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0891 - val_loss: 0.0884\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0878\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0882 - val_loss: 0.0874\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0874\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0877 - val_loss: 0.0867\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0874 - val_loss: 0.0867\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0873 - val_loss: 0.0866\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0871 - val_loss: 0.0863\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0862\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0866 - val_loss: 0.0863\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0863 - val_loss: 0.0859\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0864 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0858\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0852\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0853 - val_loss: 0.0850\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0851 - val_loss: 0.0846\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0847\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0843\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0842\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0846 - val_loss: 0.0841\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0842\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0841\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 32), found shape=(None, 64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 32), found shape=(None, 64)\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alike-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3410 - val_loss: 0.1598\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1535 - val_loss: 0.1374\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1349 - val_loss: 0.1247\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1244 - val_loss: 0.1171\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1176 - val_loss: 0.1116\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1116 - val_loss: 0.1071\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1078 - val_loss: 0.1051\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1055 - val_loss: 0.1026\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1033 - val_loss: 0.1014\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1020 - val_loss: 0.0993\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1003 - val_loss: 0.0984\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0988 - val_loss: 0.0968\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0977 - val_loss: 0.0956\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0964 - val_loss: 0.0945\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0953 - val_loss: 0.0937\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0925 - val_loss: 0.0912\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0914\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0916 - val_loss: 0.0906\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0911 - val_loss: 0.0906\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0912 - val_loss: 0.0906\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0908 - val_loss: 0.0895\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0899 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0898 - val_loss: 0.0887\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0892 - val_loss: 0.0884\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0888 - val_loss: 0.0880\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.0877\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0877 - val_loss: 0.0870\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0872 - val_loss: 0.0865\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0862\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.0859\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0863 - val_loss: 0.0858\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0856\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0853\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0859 - val_loss: 0.0856\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0853\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0854 - val_loss: 0.0847\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0848\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0853 - val_loss: 0.0845\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0848 - val_loss: 0.0845\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0846\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0843\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'genfromtxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genfromtxt' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "returning-america",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3450 - val_loss: 0.1670\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1573 - val_loss: 0.1366\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1344 - val_loss: 0.1244\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1239 - val_loss: 0.1178\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1179 - val_loss: 0.1138\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1126 - val_loss: 0.1075\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1079 - val_loss: 0.1047\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1055 - val_loss: 0.1027\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1032 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1017 - val_loss: 0.0994\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1001 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0988 - val_loss: 0.0970\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0976 - val_loss: 0.0962\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0968 - val_loss: 0.0948\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0957 - val_loss: 0.0951\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0951 - val_loss: 0.0934\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0920\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0911\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.0903\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0908 - val_loss: 0.0899\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0905 - val_loss: 0.0894\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0901 - val_loss: 0.0891\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0896 - val_loss: 0.0888\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0895 - val_loss: 0.0888\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0878\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0882 - val_loss: 0.0879\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0884 - val_loss: 0.0877\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0869\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0868\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0874 - val_loss: 0.0866\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0869 - val_loss: 0.0865\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0871 - val_loss: 0.0864\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.0861\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0868 - val_loss: 0.0863\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0866 - val_loss: 0.0860\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0866 - val_loss: 0.0860\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0856\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0863 - val_loss: 0.0855\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0856\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0857\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0856 - val_loss: 0.0853\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0853\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0859 - val_loss: 0.0851\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0854 - val_loss: 0.0851\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atomic-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3373 - val_loss: 0.1733\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1637 - val_loss: 0.1411\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1390 - val_loss: 0.1283\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1279 - val_loss: 0.1196\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1200 - val_loss: 0.1137\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1140 - val_loss: 0.1098\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1108 - val_loss: 0.1069\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1077 - val_loss: 0.1044\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1053 - val_loss: 0.1023\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1030 - val_loss: 0.1008\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1010 - val_loss: 0.0992\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0997 - val_loss: 0.0978\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0984 - val_loss: 0.0967\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0974 - val_loss: 0.0965\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0965 - val_loss: 0.0946\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0958 - val_loss: 0.0944\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0950 - val_loss: 0.0937\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0938 - val_loss: 0.0930\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0931 - val_loss: 0.0922\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0925 - val_loss: 0.0917\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0906\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.0902\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0912 - val_loss: 0.0900\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0904 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0898 - val_loss: 0.0894\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0896 - val_loss: 0.0885\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0878\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0878\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.0874\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0881 - val_loss: 0.0872\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0876 - val_loss: 0.0870\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0875 - val_loss: 0.0869\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0874 - val_loss: 0.0865\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0872 - val_loss: 0.0866\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0870 - val_loss: 0.0867\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0869 - val_loss: 0.0861\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0867 - val_loss: 0.0862\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0864 - val_loss: 0.0864\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0865 - val_loss: 0.0856\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0861 - val_loss: 0.0855\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0852\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0847\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-surprise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
