{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "played-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3772 - val_loss: 0.1857\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1766 - val_loss: 0.1521\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1480 - val_loss: 0.1327\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1306 - val_loss: 0.1207\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1199 - val_loss: 0.1131\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1128 - val_loss: 0.1075\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1075 - val_loss: 0.1031\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1036 - val_loss: 0.0998\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1003 - val_loss: 0.0975\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0957\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0968 - val_loss: 0.0946\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0939\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0952 - val_loss: 0.0934\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0944 - val_loss: 0.0931\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0941 - val_loss: 0.0929\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0920\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0920\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0919\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0932 - val_loss: 0.0918\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0931 - val_loss: 0.0917\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0917\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0930 - val_loss: 0.0916\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0917\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs)\n",
    "\n",
    "# Use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "veterinary-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3884 - val_loss: 0.1994\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1897 - val_loss: 0.1624\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1584 - val_loss: 0.1443\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1422 - val_loss: 0.1331\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1320 - val_loss: 0.1248\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1248 - val_loss: 0.1190\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1189 - val_loss: 0.1147\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1152 - val_loss: 0.1117\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1121 - val_loss: 0.1091\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1099 - val_loss: 0.1075\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1084 - val_loss: 0.1063\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1072 - val_loss: 0.1054\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1065 - val_loss: 0.1047\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1059 - val_loss: 0.1042\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1052 - val_loss: 0.1037\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1050 - val_loss: 0.1033\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1043 - val_loss: 0.1029\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1041 - val_loss: 0.1025\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1037 - val_loss: 0.1022\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1035 - val_loss: 0.1020\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1030 - val_loss: 0.1017\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1028 - val_loss: 0.1014\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1024 - val_loss: 0.1012\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1010\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1020 - val_loss: 0.1008\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1018 - val_loss: 0.1006\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1016 - val_loss: 0.1004\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1014 - val_loss: 0.1002\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1013 - val_loss: 0.1000\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0999\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0998\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1008 - val_loss: 0.0996\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1006 - val_loss: 0.0995\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1005 - val_loss: 0.0993\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1003 - val_loss: 0.0992\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1003 - val_loss: 0.0991\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1002 - val_loss: 0.0990\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.0989\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1000 - val_loss: 0.0988\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0987\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0998 - val_loss: 0.0985\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0985\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.0984\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0995 - val_loss: 0.0984\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0996 - val_loss: 0.0982\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0994 - val_loss: 0.0982\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0991 - val_loss: 0.0981\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0991 - val_loss: 0.0979\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0988 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0992 - val_loss: 0.0978\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0977\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0988 - val_loss: 0.0976\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0976\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0987 - val_loss: 0.0974\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0985 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0973\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0984 - val_loss: 0.0973\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0973\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - val_loss: 0.0971\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0970\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0968\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0981 - val_loss: 0.0968\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.0967\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0976 - val_loss: 0.0966\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.0965\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0975 - val_loss: 0.0965\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0964\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0962\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0961\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0960\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0961\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0960\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0959\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0958\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sharp-cheese",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_17/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_17/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "present-treaty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.2003\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1897 - val_loss: 0.1634\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1587 - val_loss: 0.1424\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1406 - val_loss: 0.1302\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1294 - val_loss: 0.1221\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1221 - val_loss: 0.1162\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1165 - val_loss: 0.1123\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1127 - val_loss: 0.1096\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1103 - val_loss: 0.1078\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1086 - val_loss: 0.1065\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1075 - val_loss: 0.1055\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1065 - val_loss: 0.1048\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1057 - val_loss: 0.1041\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1051 - val_loss: 0.1036\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1048 - val_loss: 0.1032\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1044 - val_loss: 0.1028\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1039 - val_loss: 0.1024\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1035 - val_loss: 0.1021\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1032 - val_loss: 0.1019\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1031 - val_loss: 0.1016\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1026 - val_loss: 0.1013\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1023 - val_loss: 0.1011\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1023 - val_loss: 0.1008\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1018 - val_loss: 0.1006\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1017 - val_loss: 0.1005\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1016 - val_loss: 0.1002\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1012 - val_loss: 0.1001\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1010 - val_loss: 0.0999\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1011 - val_loss: 0.0998\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1009 - val_loss: 0.0996\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1005 - val_loss: 0.0995\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0994\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1004 - val_loss: 0.0992\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0990\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.1001 - val_loss: 0.0989\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0998 - val_loss: 0.0988\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0999 - val_loss: 0.0988\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0999 - val_loss: 0.0987\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0996 - val_loss: 0.0985\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0997 - val_loss: 0.0985\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0995 - val_loss: 0.0983\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0993 - val_loss: 0.0982\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.0982\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0991 - val_loss: 0.0980\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0990 - val_loss: 0.0980\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0989 - val_loss: 0.0979\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0989 - val_loss: 0.0978\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0978\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0988 - val_loss: 0.0976\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0987 - val_loss: 0.0976\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0975\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0974\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0985 - val_loss: 0.0974\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - val_loss: 0.0974\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0983 - val_loss: 0.0973\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0983 - val_loss: 0.0972\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0984 - val_loss: 0.0972\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0972\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0982 - val_loss: 0.0971\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0979 - val_loss: 0.0970\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - val_loss: 0.0970\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - val_loss: 0.0969\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0969\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0969\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0980 - val_loss: 0.0968\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0968\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0977 - val_loss: 0.0967\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0966\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0975 - val_loss: 0.0966\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0975 - val_loss: 0.0966\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0965\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0976 - val_loss: 0.0965\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0964\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0964\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0963\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0973 - val_loss: 0.0963\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0962\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0964\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0963\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0962\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0972 - val_loss: 0.0961\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0974 - val_loss: 0.0962\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0961\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0971 - val_loss: 0.0960\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0960\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0960\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0968 - val_loss: 0.0960\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0968 - val_loss: 0.0959\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0970 - val_loss: 0.0959\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 0.0969 - val_loss: 0.0958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aware-schedule",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (AutoEncoder.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    encoding_dim = 784 128\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "criminal-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3318 - val_loss: 0.1638\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1536 - val_loss: 0.1328\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1315 - val_loss: 0.1225\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1219 - val_loss: 0.1167\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1157 - val_loss: 0.1102\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1107 - val_loss: 0.1062\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1067 - val_loss: 0.1033\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1039 - val_loss: 0.1015\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1020 - val_loss: 0.0999\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.1001 - val_loss: 0.0977\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0983 - val_loss: 0.0967\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0972 - val_loss: 0.0952\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0958 - val_loss: 0.0940\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0948 - val_loss: 0.0931\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0936 - val_loss: 0.0919\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0926 - val_loss: 0.0918\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0922 - val_loss: 0.0906\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0914 - val_loss: 0.0901\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0910 - val_loss: 0.0898\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0902 - val_loss: 0.0894\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0898 - val_loss: 0.0890\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0895 - val_loss: 0.0887\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0894 - val_loss: 0.0881\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0887 - val_loss: 0.0878\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.0873\n",
      "Epoch 27/100\n",
      " 81/235 [=========>....................] - ETA: 0s - loss: 0.0877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m autoencoder.fit(x_train, x_train,\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "human-colony",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_210/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_210/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-exclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-pepper",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bacterial-designation",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_216/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_216/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unique-protein",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 32 and 128 for '{{node dense_222/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_222/MatMul/ReadVariableOp)' with input shapes: [?,32], [128,784]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aggressive-three",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(32, 128)' with type '<class 'tuple'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# This is our encoded (32-dimensional) input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mencoded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# Retrieve the last layer of the autoencoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[0;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m     input_layer_config.update(\n\u001b[1;32m    308\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[0;32m--> 309\u001b[0;31m   \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         input_tensor = backend.placeholder(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[0;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[1;32m   1244\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaggedKerasTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m       spec = tensor_spec.TensorSpec(\n\u001b[0m\u001b[1;32m   1247\u001b[0m           shape=shape, dtype=dtype, name=name)\n\u001b[1;32m   1248\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype, name)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mnot\u001b[0m \u001b[0mconvertible\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \"\"\"\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         six.raise_from(\n\u001b[0m\u001b[1;32m    204\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[1;32m    205\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(32, 128)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "peripheral-shaft",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (AutoEncoder.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    encoding_dim = 32 128\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "particular-second",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3336 - val_loss: 0.1676\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1623 - val_loss: 0.1395\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1365 - val_loss: 0.1268\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1260 - val_loss: 0.1191\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1189 - val_loss: 0.1124\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1130 - val_loss: 0.1088\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1097 - val_loss: 0.1064\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1071 - val_loss: 0.1042\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1049 - val_loss: 0.1028\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1034 - val_loss: 0.1019\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1000\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1008 - val_loss: 0.0986\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0998 - val_loss: 0.0974\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0964\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0973 - val_loss: 0.0957\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0964 - val_loss: 0.0948\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0956 - val_loss: 0.0940\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0949 - val_loss: 0.0935\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0943 - val_loss: 0.0927\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0934 - val_loss: 0.0925\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0925 - val_loss: 0.0913\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0920 - val_loss: 0.0907\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0910 - val_loss: 0.0903\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0907 - val_loss: 0.0896\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0905 - val_loss: 0.0896\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0901 - val_loss: 0.0895\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0899 - val_loss: 0.0889\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0895 - val_loss: 0.0890\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0890 - val_loss: 0.0882\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0884\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0881\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0884 - val_loss: 0.0876\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0881 - val_loss: 0.0876\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0879 - val_loss: 0.0874\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0877 - val_loss: 0.0870\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0877 - val_loss: 0.0872\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0867\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0871 - val_loss: 0.0866\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - val_loss: 0.0862\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0867 - val_loss: 0.0863\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - val_loss: 0.0864\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0866 - val_loss: 0.0859\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - val_loss: 0.0861\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0855\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - val_loss: 0.0858\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - val_loss: 0.0856\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0860 - val_loss: 0.0855\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - val_loss: 0.0853\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0857 - val_loss: 0.0851\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0856 - val_loss: 0.0851\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0851\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0852 - val_loss: 0.0847\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0847\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0848\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0847\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0845\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0844\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0844\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0848 - val_loss: 0.0843\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0842\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - val_loss: 0.0842\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0843\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0841\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0844\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0840\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0841\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0840\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0838\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0843 - val_loss: 0.0839\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0837\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0839\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0836\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0838\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0837\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0836\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0837\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0837\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0835\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0835\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0833\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0834\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0835 - val_loss: 0.0833\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0833\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0833\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0832\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0830\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0832 - val_loss: 0.0831\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0829\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0831 - val_loss: 0.0828\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_90: expected shape=(None, 128), found shape=(None, 32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_90: expected shape=(None, 128), found shape=(None, 32)\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "accurate-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3395 - val_loss: 0.1663\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1579 - val_loss: 0.1354\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1333 - val_loss: 0.1226\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1222 - val_loss: 0.1146\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1153 - val_loss: 0.1097\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1098 - val_loss: 0.1069\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1071 - val_loss: 0.1039\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1043 - val_loss: 0.1016\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1023 - val_loss: 0.1003\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1006 - val_loss: 0.0988\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0996 - val_loss: 0.0978\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0982 - val_loss: 0.0963\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0969 - val_loss: 0.0957\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0958 - val_loss: 0.0944\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0927 - val_loss: 0.0914\n",
      "Epoch 18/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0922 - val_loss: 0.0911\n",
      "Epoch 19/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0917 - val_loss: 0.0903\n",
      "Epoch 20/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0909 - val_loss: 0.0897\n",
      "Epoch 21/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 22/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0898 - val_loss: 0.0888\n",
      "Epoch 23/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 24/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0888 - val_loss: 0.0879\n",
      "Epoch 25/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0884 - val_loss: 0.0875\n",
      "Epoch 26/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0879 - val_loss: 0.0873\n",
      "Epoch 27/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0876 - val_loss: 0.0869\n",
      "Epoch 28/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0874 - val_loss: 0.0863\n",
      "Epoch 29/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0870 - val_loss: 0.0861\n",
      "Epoch 30/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0865 - val_loss: 0.0857\n",
      "Epoch 31/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0865\n",
      "Epoch 32/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - val_loss: 0.0853\n",
      "Epoch 33/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - val_loss: 0.0850\n",
      "Epoch 34/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0856 - val_loss: 0.0852\n",
      "Epoch 35/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 36/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0848\n",
      "Epoch 37/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0849\n",
      "Epoch 38/100\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0849 - val_loss: 0.0845\n",
      "Epoch 39/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0843\n",
      "Epoch 40/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0841\n",
      "Epoch 41/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0839\n",
      "Epoch 42/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 43/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0838\n",
      "Epoch 44/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0836\n",
      "Epoch 45/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0839 - val_loss: 0.0836\n",
      "Epoch 46/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 47/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0831\n",
      "Epoch 48/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0832\n",
      "Epoch 49/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0831\n",
      "Epoch 50/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0831\n",
      "Epoch 51/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0826\n",
      "Epoch 52/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0829 - val_loss: 0.0825\n",
      "Epoch 53/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0830 - val_loss: 0.0825\n",
      "Epoch 54/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 55/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0827 - val_loss: 0.0826\n",
      "Epoch 56/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0828 - val_loss: 0.0828\n",
      "Epoch 57/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0824 - val_loss: 0.0819\n",
      "Epoch 58/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0821\n",
      "Epoch 59/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0820\n",
      "Epoch 60/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0819\n",
      "Epoch 61/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 62/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0817\n",
      "Epoch 63/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0817\n",
      "Epoch 64/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0815\n",
      "Epoch 65/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0819 - val_loss: 0.0813\n",
      "Epoch 66/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - val_loss: 0.0815\n",
      "Epoch 67/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0813\n",
      "Epoch 68/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0815 - val_loss: 0.0814\n",
      "Epoch 69/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0813 - val_loss: 0.0811\n",
      "Epoch 70/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0812\n",
      "Epoch 71/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0814\n",
      "Epoch 72/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0810\n",
      "Epoch 73/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0812\n",
      "Epoch 74/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0814 - val_loss: 0.0809\n",
      "Epoch 75/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0808\n",
      "Epoch 76/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0810 - val_loss: 0.0809\n",
      "Epoch 77/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0811 - val_loss: 0.0807\n",
      "Epoch 78/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0810\n",
      "Epoch 79/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0807\n",
      "Epoch 80/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0807 - val_loss: 0.0804\n",
      "Epoch 81/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0807 - val_loss: 0.0805\n",
      "Epoch 82/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0808 - val_loss: 0.0804\n",
      "Epoch 83/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0802\n",
      "Epoch 84/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0801\n",
      "Epoch 85/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0804 - val_loss: 0.0803\n",
      "Epoch 86/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0805 - val_loss: 0.0801\n",
      "Epoch 87/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0802 - val_loss: 0.0801\n",
      "Epoch 88/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0803 - val_loss: 0.0800\n",
      "Epoch 89/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0801\n",
      "Epoch 90/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0800\n",
      "Epoch 91/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0800\n",
      "Epoch 92/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0801 - val_loss: 0.0802\n",
      "Epoch 93/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0800 - val_loss: 0.0800\n",
      "Epoch 94/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0797\n",
      "Epoch 95/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0797\n",
      "Epoch 96/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0797 - val_loss: 0.0796\n",
      "Epoch 97/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - val_loss: 0.0797\n",
      "Epoch 98/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0799 - val_loss: 0.0799\n",
      "Epoch 99/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0798 - val_loss: 0.0796\n",
      "Epoch 100/100\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0796 - val_loss: 0.0795\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'decoded_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoded_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fundamental-titanium",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create the decoder model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m     return core_ops.dense(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/layers/ops/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, kernel, bias, activation, dtype)\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;31m# Broadcast kernel to inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5546\u001b[0m     \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5547\u001b[0m   \u001b[0mtranspose_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5548\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   5549\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5550\u001b[0m                   name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    746\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    588\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3528\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3529\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3530\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   2016\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 128 and 64 for '{{node dense_257/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_257/MatMul/ReadVariableOp)' with input shapes: [?,128], [64,128]."
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriental-system",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3378 - val_loss: 0.1620\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1531 - val_loss: 0.1333\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1316 - val_loss: 0.1230\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1225 - val_loss: 0.1152\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1153 - val_loss: 0.1101\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1104 - val_loss: 0.1067\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1069 - val_loss: 0.1036\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1044 - val_loss: 0.1018\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1023 - val_loss: 0.1000\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1009 - val_loss: 0.0985\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0995 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0982 - val_loss: 0.0961\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0968 - val_loss: 0.0951\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0962 - val_loss: 0.0945\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0950 - val_loss: 0.0936\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0919\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0922 - val_loss: 0.0909\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0916 - val_loss: 0.0903\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0909 - val_loss: 0.0897\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0905 - val_loss: 0.0894\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0900 - val_loss: 0.0892\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0899 - val_loss: 0.0887\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0894 - val_loss: 0.0885\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0890 - val_loss: 0.0884\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0877\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0883 - val_loss: 0.0876\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0880 - val_loss: 0.0871\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0878 - val_loss: 0.0873\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0866\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0873 - val_loss: 0.0864\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0861\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0867 - val_loss: 0.0860\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0866 - val_loss: 0.0858\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0863 - val_loss: 0.0854\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0862 - val_loss: 0.0851\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0850\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0850 - val_loss: 0.0848\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0851 - val_loss: 0.0843\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0848 - val_loss: 0.0845\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0842\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0850 - val_loss: 0.0841\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0846 - val_loss: 0.0847\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0842\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'genfromtxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genfromtxt' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "professional-guitar",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3428 - val_loss: 0.1663\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1559 - val_loss: 0.1349\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1331 - val_loss: 0.1226\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1225 - val_loss: 0.1165\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1167 - val_loss: 0.1117\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1122 - val_loss: 0.1081\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1082 - val_loss: 0.1048\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1055 - val_loss: 0.1026\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1032 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1013 - val_loss: 0.0990\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0998 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0984 - val_loss: 0.0965\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0972 - val_loss: 0.0950\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0960 - val_loss: 0.0942\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0951 - val_loss: 0.0937\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0945 - val_loss: 0.0929\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0935 - val_loss: 0.0925\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0924 - val_loss: 0.0910\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0905\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0909 - val_loss: 0.0899\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0904 - val_loss: 0.0895\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0900 - val_loss: 0.0896\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0893 - val_loss: 0.0888\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0891 - val_loss: 0.0884\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0878\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0882 - val_loss: 0.0874\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0874\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0877 - val_loss: 0.0867\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0874 - val_loss: 0.0867\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0873 - val_loss: 0.0866\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0871 - val_loss: 0.0863\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0862\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0866 - val_loss: 0.0863\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0863 - val_loss: 0.0859\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0864 - val_loss: 0.0857\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0858\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0852\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0853 - val_loss: 0.0850\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0851 - val_loss: 0.0846\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0847\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0849 - val_loss: 0.0843\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0842\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0846 - val_loss: 0.0841\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0844 - val_loss: 0.0842\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0845 - val_loss: 0.0841\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 32), found shape=(None, 64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Note that we take them from the *test* set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mencoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdecoded_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/endington/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_11: expected shape=(None, 32), found shape=(None, 64)\n"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alike-advantage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.3410 - val_loss: 0.1598\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1535 - val_loss: 0.1374\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1349 - val_loss: 0.1247\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1244 - val_loss: 0.1171\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1176 - val_loss: 0.1116\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1116 - val_loss: 0.1071\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1078 - val_loss: 0.1051\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.1055 - val_loss: 0.1026\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1033 - val_loss: 0.1014\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1020 - val_loss: 0.0993\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1003 - val_loss: 0.0984\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0988 - val_loss: 0.0968\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0977 - val_loss: 0.0956\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0964 - val_loss: 0.0945\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0953 - val_loss: 0.0937\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0948 - val_loss: 0.0932\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0925 - val_loss: 0.0912\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0914\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0916 - val_loss: 0.0906\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0911 - val_loss: 0.0906\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0912 - val_loss: 0.0906\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0908 - val_loss: 0.0895\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0903 - val_loss: 0.0892\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0899 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0898 - val_loss: 0.0887\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0892 - val_loss: 0.0884\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0888 - val_loss: 0.0880\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.0877\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0877 - val_loss: 0.0870\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0872 - val_loss: 0.0865\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0870 - val_loss: 0.0862\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.0859\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0863 - val_loss: 0.0858\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0856\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0853\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0859 - val_loss: 0.0856\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0853\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0854 - val_loss: 0.0847\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0852 - val_loss: 0.0848\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0853 - val_loss: 0.0845\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0848 - val_loss: 0.0845\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0846\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0848 - val_loss: 0.0843\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'genfromtxt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Use Matplotlib (don't ask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genfromtxt' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "returning-america",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3450 - val_loss: 0.1670\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1573 - val_loss: 0.1366\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1344 - val_loss: 0.1244\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1239 - val_loss: 0.1178\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1179 - val_loss: 0.1138\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1126 - val_loss: 0.1075\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1079 - val_loss: 0.1047\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1055 - val_loss: 0.1027\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1032 - val_loss: 0.1007\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1017 - val_loss: 0.0994\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1001 - val_loss: 0.0978\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0988 - val_loss: 0.0970\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0976 - val_loss: 0.0962\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0968 - val_loss: 0.0948\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0957 - val_loss: 0.0951\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0951 - val_loss: 0.0934\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0941 - val_loss: 0.0927\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0936 - val_loss: 0.0922\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0928 - val_loss: 0.0920\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0922 - val_loss: 0.0912\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0911\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.0903\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0908 - val_loss: 0.0899\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0905 - val_loss: 0.0894\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0901 - val_loss: 0.0891\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0896 - val_loss: 0.0888\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0895 - val_loss: 0.0888\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0878\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0882 - val_loss: 0.0879\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0884 - val_loss: 0.0877\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0879 - val_loss: 0.0869\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0869\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0875 - val_loss: 0.0868\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0874 - val_loss: 0.0866\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0869 - val_loss: 0.0865\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0871 - val_loss: 0.0864\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.0861\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0868 - val_loss: 0.0863\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0866 - val_loss: 0.0860\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0866 - val_loss: 0.0860\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0862 - val_loss: 0.0856\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0863 - val_loss: 0.0855\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0856\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0860 - val_loss: 0.0857\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0856 - val_loss: 0.0853\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0853\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0859 - val_loss: 0.0851\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0854 - val_loss: 0.0851\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'matplotlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matplotlib' is not defined"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "atomic-internship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3373 - val_loss: 0.1733\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1637 - val_loss: 0.1411\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1390 - val_loss: 0.1283\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1279 - val_loss: 0.1196\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1200 - val_loss: 0.1137\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1140 - val_loss: 0.1098\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1108 - val_loss: 0.1069\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.1077 - val_loss: 0.1044\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1053 - val_loss: 0.1023\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1030 - val_loss: 0.1008\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1010 - val_loss: 0.0992\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0997 - val_loss: 0.0978\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0984 - val_loss: 0.0967\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0974 - val_loss: 0.0965\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0965 - val_loss: 0.0946\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0958 - val_loss: 0.0944\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0950 - val_loss: 0.0937\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0943 - val_loss: 0.0930\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0938 - val_loss: 0.0930\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0931 - val_loss: 0.0922\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0925 - val_loss: 0.0917\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0921 - val_loss: 0.0912\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0919 - val_loss: 0.0906\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0913 - val_loss: 0.0902\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0912 - val_loss: 0.0900\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0906 - val_loss: 0.0901\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0904 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0898 - val_loss: 0.0894\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0896 - val_loss: 0.0885\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0892 - val_loss: 0.0885\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0889 - val_loss: 0.0883\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0878\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0885 - val_loss: 0.0878\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0881 - val_loss: 0.0874\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0881 - val_loss: 0.0872\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0876 - val_loss: 0.0870\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0875 - val_loss: 0.0869\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0874 - val_loss: 0.0865\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 2s 7ms/step - loss: 0.0872 - val_loss: 0.0866\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.0870 - val_loss: 0.0867\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0869 - val_loss: 0.0861\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0867 - val_loss: 0.0862\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0864 - val_loss: 0.0864\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0865 - val_loss: 0.0856\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0861 - val_loss: 0.0855\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0859 - val_loss: 0.0852\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0854 - val_loss: 0.0847\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib.pyplot' has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Desktop/machinelearning/Autoencoder/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'encoded1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m  \u001b[0;31m# How many digits we will display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib.pyplot' has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cooked-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3384 - val_loss: 0.1678\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1604 - val_loss: 0.1380\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1361 - val_loss: 0.1273\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1266 - val_loss: 0.1196\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1197 - val_loss: 0.1141\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1146 - val_loss: 0.1104\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1111 - val_loss: 0.1078\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1083 - val_loss: 0.1065\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1065 - val_loss: 0.1038\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1045 - val_loss: 0.1019\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1024 - val_loss: 0.1000\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1005 - val_loss: 0.0982\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0991 - val_loss: 0.0971\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0977 - val_loss: 0.0959\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0967 - val_loss: 0.0951\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0954 - val_loss: 0.0942\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0947 - val_loss: 0.0937\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0943 - val_loss: 0.0929\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0920\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0929 - val_loss: 0.0921\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0924 - val_loss: 0.0913\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0915 - val_loss: 0.0910\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0916 - val_loss: 0.0907\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0912 - val_loss: 0.0901\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0908 - val_loss: 0.0894\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0905 - val_loss: 0.0896\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0900 - val_loss: 0.0892\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0896 - val_loss: 0.0887\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0894 - val_loss: 0.0886\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0892 - val_loss: 0.0883\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0880\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0885 - val_loss: 0.0879\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0882 - val_loss: 0.0874\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0878 - val_loss: 0.0872\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - val_loss: 0.0868\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0871\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0870 - val_loss: 0.0863\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0868 - val_loss: 0.0861\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0867 - val_loss: 0.0861\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - val_loss: 0.0856\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0861 - val_loss: 0.0856\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0857 - val_loss: 0.0850\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0849\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0852 - val_loss: 0.0846\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0847\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0848 - val_loss: 0.0841\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0843\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32 into shape (4,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Documents/GitHub/Machinelearning/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (4,32)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIsAAAHWCAYAAABHfnpiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMjklEQVR4nO3af6jd913H8ed7iXFQ5wbmCiM/bIaZNehg3SUWBlpYhSR/JH9MJAGZlbrL0IjgECKTKvEPmYLCMDqDlrmBzbL+IVfMiKKVgpiaW7bVJiHjLv7IjYVmXe0/w2aBt3/cs3l6d2/OKzfn3nNSnw+4cL7f7+d8zzv0yfd8zzmt7kZKvG3SA+j+YSyKGYtixqKYsShmLIqNjKWqnqqqV6rqpTWOV1V9qqoWq+rFqnp4/GNqGiRXls8AB+5w/CCwd/A3B/zJvY+laTQylu5+DvjGHZYcAT7byy4A76qqd49rQE2Pcdyz7ACuD20vDfbpLWbrZr5YVc2x/FbFAw888IGHHnpoM19eAy+88MLXu3vmbp83jlhuALuGtncO9n2X7j4NnAaYnZ3thYWFMby87lZV/cd6njeOt6F54CODT0WPAK9398tjOK+mzMgrS1U9DTwKbK+qJeC3gO8B6O5PA+eAQ8Ai8E3gFzZqWE3WyFi6+9iI4w388tgm0tTyG1zFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRbEolqo6UFVXq2qxqk6scnx3VT1bVV+qqher6tD4R9WkjYylqrYAp4CDwD7gWFXtW7HsN4Gz3f1+4Cjwx+MeVJOXXFn2A4vdfa27bwFngCMr1jTw/YPH7wT+a3wjalpsDdbsAK4PbS8BP7FizW8Df1tVvwI8ADw2luk0VcZ1g3sM+Ex37wQOAZ+rqu86d1XNVdVCVS3cvHlzTC+tzZLEcgPYNbS9c7Bv2BPAWYDu/mfg7cD2lSfq7tPdPdvdszMzM+ubWBOTxHIR2FtVe6pqG8s3sPMr1vwn8CGAqvpRlmPx0vEWMzKW7r4NHAfOA1dY/tRzqapOVtXhwbKPAx+tqq8ATwOPd3dv1NCajOQGl+4+B5xbse/JoceXgQ+OdzRNG7/BVcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUi2KpqgNVdbWqFqvqxBprfraqLlfVpar6y/GOqWmwddSCqtoCnAJ+GlgCLlbVfHdfHlqzF/gN4IPd/VpV/eBGDazJSa4s+4HF7r7W3beAM8CRFWs+Cpzq7tcAuvuV8Y6paZDEsgO4PrS9NNg37L3Ae6vqn6rqQlUdGNeAmh4j34bu4jx7gUeBncBzVfXj3f3fw4uqag6YA9i9e/eYXlqbJbmy3AB2DW3vHOwbtgTMd/e3uvvfgK+yHM+bdPfp7p7t7tmZmZn1zqwJSWK5COytqj1VtQ04CsyvWPNXLF9VqKrtLL8tXRvfmJoGI2Pp7tvAceA8cAU4292XqupkVR0eLDsPvFpVl4FngV/v7lc3amhNRnX3RF54dna2FxYWJvLa/99V1QvdPXu3z/MbXMWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFsSiWqjpQVVerarGqTtxh3YerqqtqdnwjalqMjKWqtgCngIPAPuBYVe1bZd07gF8Fnh/3kJoOyZVlP7DY3de6+xZwBjiyyrrfAT4J/M8Y59MUSWLZAVwf2l4a7PuOqnoY2NXdfzPG2TRl7vkGt6reBvwB8PFg7VxVLVTVws2bN+/1pbXJklhuALuGtncO9n3bO4AfA/6xqv4deASYX+0mt7tPd/dsd8/OzMysf2pNRBLLRWBvVe2pqm3AUWD+2we7+/Xu3t7dD3b3g8AF4HB3L2zIxJqYkbF0923gOHAeuAKc7e5LVXWyqg5v9ICaHluTRd19Dji3Yt+Ta6x99N7H0jTyG1zFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRbEolqo6UFVXq2qxqk6scvzXqupyVb1YVX9fVT80/lE1aSNjqaotwCngILAPOFZV+1Ys+xIw293vA54Bfm/cg2rykivLfmCxu6919y3gDHBkeEF3P9vd3xxsXgB2jndMTYMklh3A9aHtpcG+tTwBfPFehtJ02jrOk1XVzwGzwE+tcXwOmAPYvXv3OF9amyC5stwAdg1t7xzse5Oqegz4BHC4u99Y7UTdfbq7Z7t7dmZmZj3zaoKSWC4Ce6tqT1VtA44C88MLqur9wJ+yHMor4x9T02BkLN19GzgOnAeuAGe7+1JVnayqw4Nlvw98H/CFqvpyVc2vcTrdx6J7lu4+B5xbse/JocePjXkuTSG/wVXMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFDMWxYxFMWNRzFgUMxbFjEUxY1HMWBQzFsWMRTFjUcxYFItiqaoDVXW1qhar6sQqx7+3qj4/OP58VT049kk1cSNjqaotwCngILAPOFZV+1YsewJ4rbt/GPhD4JPjHlSTl1xZ9gOL3X2tu28BZ4AjK9YcAf5i8PgZ4ENVVeMbU9MgiWUHcH1oe2mwb9U13X0beB34gXEMqOmxdTNfrKrmgLnB5htV9dJmvv4YbQe+Pukh7sGPrOdJSSw3gF1D2zsH+1Zbs1RVW4F3Aq+uPFF3nwZOA1TVQnfPrmfoSbufZ4fl+dfzvORt6CKwt6r2VNU24Cgwv2LNPPDzg8c/A/xDd/d6BtL0Gnll6e7bVXUcOA9sAZ7q7ktVdRJY6O554M+Bz1XVIvANloPSW0xN6gJQVXODt6X7zv08O6x//onFovuPX/crtuGx3M8/FQSzP15VN6vqy4O/X5zEnKupqqeq6pW1vp6oZZ8a/NterKqHR560uzfsj+Ub4q8B7wG2AV8B9q1Y80vApwePjwKf38iZxjz748AfTXrWNeb/SeBh4KU1jh8CvggU8Ajw/KhzbvSV5X7+qSCZfWp193MsfzJdyxHgs73sAvCuqnr3nc650bHczz8VJLMDfHhwGX+mqnatcnxapf++7/AG9978NfBgd78P+Dv+7wr5lrTRsdzNTwXc6aeCCRg5e3e/2t1vDDb/DPjAJs02Dsl/mzfZ6Fju558KRs6+4j3+MHBlE+e7V/PARwafih4BXu/ul+/4jE24Kz8EfJXlTxafGOw7CRwePH478AVgEfgX4D2T/iRxF7P/LnCJ5U9KzwIPTXrmodmfBl4GvsXy/cgTwMeAjw2OF8v/U9vXgH8FZked029wFfMGVzFjUcxYFDMWxYxFMWNRzFgUMxbF/hehIi1M/Tp4mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distant-thomas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.3410 - val_loss: 0.1668\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1568 - val_loss: 0.1357\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1340 - val_loss: 0.1249\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1237 - val_loss: 0.1170\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1166 - val_loss: 0.1116\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1120 - val_loss: 0.1076\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1084 - val_loss: 0.1049\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1055 - val_loss: 0.1029\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1037 - val_loss: 0.1014\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1018 - val_loss: 0.0995\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1005 - val_loss: 0.0984\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0992 - val_loss: 0.0970\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0978 - val_loss: 0.0962\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0968 - val_loss: 0.0953\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0960 - val_loss: 0.0941\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0949 - val_loss: 0.0934\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0941 - val_loss: 0.0928\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0933 - val_loss: 0.0919\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0914\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0921 - val_loss: 0.0911\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0914 - val_loss: 0.0905\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0908 - val_loss: 0.0897\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0904 - val_loss: 0.0893\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0896 - val_loss: 0.0886\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0891 - val_loss: 0.0883\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0887 - val_loss: 0.0877\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0883 - val_loss: 0.0874\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0878 - val_loss: 0.0869\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0875 - val_loss: 0.0867\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0872 - val_loss: 0.0867\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0871 - val_loss: 0.0864\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0869 - val_loss: 0.0860\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0856\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0861 - val_loss: 0.0856\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0859 - val_loss: 0.0854\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0858 - val_loss: 0.0850\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0855 - val_loss: 0.0851\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0854 - val_loss: 0.0847\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0846\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0844\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0849 - val_loss: 0.0844\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - val_loss: 0.0841\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0840\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0844 - val_loss: 0.0840\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0842 - val_loss: 0.0837\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.0840\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0841 - val_loss: 0.0836\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0840 - val_loss: 0.0832\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0834\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0834 - val_loss: 0.0835\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32 into shape (4,32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Documents/GitHub/Machinelearning/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_imgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 32 into shape (4,32)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-biography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.3457 - val_loss: 0.1648\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1562 - val_loss: 0.1350\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1328 - val_loss: 0.1227\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1218 - val_loss: 0.1152\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1151 - val_loss: 0.1100\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1106 - val_loss: 0.1070\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1073 - val_loss: 0.1037\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1042 - val_loss: 0.1015\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1019 - val_loss: 0.0996\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.1003 - val_loss: 0.0980\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0986 - val_loss: 0.0968\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0970 - val_loss: 0.0954\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0961 - val_loss: 0.0945\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0951 - val_loss: 0.0930\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0937 - val_loss: 0.0927\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0928 - val_loss: 0.0910\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0919 - val_loss: 0.0904\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0910 - val_loss: 0.0897\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0904 - val_loss: 0.0892\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0897 - val_loss: 0.0884\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0890 - val_loss: 0.0882\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0885 - val_loss: 0.0876\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0883 - val_loss: 0.0873\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0878 - val_loss: 0.0871\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0865\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0869 - val_loss: 0.0862\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0869 - val_loss: 0.0859\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0863 - val_loss: 0.0856\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0862 - val_loss: 0.0857\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0861 - val_loss: 0.0853\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0857 - val_loss: 0.0852\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0853 - val_loss: 0.0848\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0845\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0852 - val_loss: 0.0844\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0849 - val_loss: 0.0842\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - val_loss: 0.0843\n",
      "Epoch 37/50\n",
      "210/235 [=========================>....] - ETA: 0s - loss: 0.0844"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/c/Users/Princ/Documents/GitHub/Machinelearning/AutoEncoder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m autoencoder.fit(x_train, x_train,\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run AutoEncoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-rapid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
